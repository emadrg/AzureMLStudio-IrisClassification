# -*- coding: utf-8 -*-
"""Notebook 1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1a-S-thcsiiFlrYLh8Vbr2zbyaoxysbPE
"""

from pyspark.sql import SparkSession
from pyspark.sql.functions import col, when

# Conectare la baza de datea
spark = SparkSession.builder.getOrCreate()
data = spark.read \
    .format("jdbc") \
    .option("url", "jdbc:sqlserver://neuraldb-server.database.windows.net:1433;databaseName=neuraldb") \
    .option("dbtable", "RawData") \
    .option("user", "sqladmin") \
    .option("password", "Copernic@1234") \
    .load()

# Normalizare
for col_name in ["SepalLengthCm", "SepalWidthCm", "PetalLengthCm", "PetalWidthCm"]:
    max_val = data.agg({col_name: "max"}).collect()[0][0]
    min_val = data.agg({col_name: "min"}).collect()[0][0]
    data = data.withColumn(col_name, (col(col_name) - min_val) / (max_val - min_val))

# One-Hot Encoding pentru Species
data = data.withColumn("Setosa", when(col("Species") == "Iris-setosa", 1).otherwise(0)) \
           .withColumn("Versicolor", when(col("Species") == "Iris-versicolor", 1).otherwise(0)) \
           .withColumn("Virginica", when(col("Species") == "Iris-virginica", 1).otherwise(0))

# Salvează datele preprocesate în tabelul `PreprocessedData` (creează tabela în prealabil)
data.write \
    .format("jdbc") \
    .option("url", "jdbc:sqlserver://neuraldb-server.database.windows.net:1433;databaseName=neuraldb") \
    .option("dbtable", "PreprocessedData") \
    .option("user", "sqladmin") \
    .option("password", "Copernic@1234") \
    .mode("overwrite") \
    .save()

!pip install --upgrade scikit-learn==1.3.2 joblib

import pyodbc
import pandas as pd
sql_connection = pyodbc.connect(
    "Driver={ODBC Driver 18 for SQL Server};"
    "Server=neuraldb-server.database.windows.net;"
    "Database=neuraldb;"
    "UID=sqladmin;"
    "PWD=Copernic@1234;"
)

df = pd.read_sql("SELECT * FROM PreprocessedData", con=sql_connection)

X = df[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']]
y = df[['Setosa', 'Versicolor', 'Virginica']]  # Convert one-hot to categorical labels
#y = y.map({'Setosa': 0, 'Versicolor': 1, 'Virginica': 2})  # Convert labels to integer values
y

from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
import pyodbc
import pandas as pd

sql_connection = pyodbc.connect(
    "Driver={ODBC Driver 18 for SQL Server};"
    "Server=neuraldb-server.database.windows.net;"
    "Database=neuraldb;"
    "UID=sqladmin;"
    "PWD=Copernic@1234;"
)

df = pd.read_sql("SELECT * FROM PreprocessedData", con=sql_connection)


X = df[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']]
y = df[['Setosa', 'Versicolor', 'Virginica']].idxmax(axis=1)
y = y.map({'Setosa': 0, 'Versicolor': 1, 'Virginica': 2})


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=None)


model = MLPClassifier(
    hidden_layer_sizes=(64, 32, 16),  # Increased number of layers
    activation="relu",  # Better activation function
    solver="adam",  # Adaptive optimizer
    alpha=0.0001,  # Regularization to prevent overfitting
    max_iter=2000,  # More iterations for stability
    random_state=None
)


model.fit(X_train, y_train)


y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

print(f"Accuracy: {accuracy:.4f}")

model

config_content = '''
{
    "subscription_id": "d26fc747-267a-4488-8e73-12f1299987a6",
    "resource_group": "neuraldb-resources",
    "workspace_name": "machinelearningname"
}
'''
with open("config.json", "w") as f:
    f.write(config_content)

type(model)

# import joblib
# joblib.dump(model, 'v9_iris_model_neural_network.pkl')

import pickle

with open("v16_iris_model_neural_network.pkl", "wb") as file:
    pickle.dump(model, file)

from azureml.core import Model
from azureml.core import Workspace
ws = Workspace.get(name="machinelearningname", subscription_id="d26fc747-267a-4488-8e73-12f1299987a6", resource_group="neuraldb-resources")
model_registration = Model.register(
    workspace=ws,
    model_path='v16_iris_model_neural_network.pkl',
    model_name='v16_iris_model_neural_network',
    description='neural net for iris dataset v16'
)

import pickle

model_path = 'v11_iris_model_neural_network.pkl'

try:
    with open(model_path, 'rb') as file:
        model = pickle.load(file)
        print("Modelul a fost încărcat cu succes!")
        print("Tipul modelului:", type(model))
except Exception as e:
    print("Eroare la încărcarea modelului:", e)

import sklearn
import numpy
print("Scikit-learn version:", sklearn.__version__)
print("NumPy version:", numpy.__version__)

!pip install --upgrade scikit-learn

!pip install --upgrade numpy

import joblib
model = joblib.load("v2_iris_model_neural_network.pkl")
print(model.__module__, model.__class__.__name__)

import numpy
print(numpy.__version__)

!pip uninstall numpy -y

!pip install numpy==1.21.5

!pip install --upgrade --force-reinstall numpy==1.21.5

!python -c "import numpy; print(numpy.__version__)"